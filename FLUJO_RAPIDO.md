# GU√çA R√ÅPIDA DE FLUJO - Detector de Deepfakes

## üéØ Objetivo del Proyecto
Detectar si una imagen de rostro es REAL o FAKE usando ResNet18 + Grad-CAM para explicabilidad.

---

## üìä FLUJO COMPLETO (De datos a producci√≥n)

### PASO 1: Preprocesamiento de Datos
**Archivo:** `src/data/extract_and_crop_ffpp.py`

**Qu√© hace:**
- Lee 7,000 videos del dataset FaceForensics++ (1,000 reales + 6,000 fake)
- Extrae 10 frames uniformemente de cada video
- Detecta rostros con MTCNN (confianza >95%)
- Recorta rostros y guarda como im√°genes
- **Output:** 47,994 im√°genes en `data/processed/ffpp/`

**Comando:**
```bash
python src/data/extract_and_crop_ffpp.py
```

**Resultado:**
```
data/processed/ffpp/
‚îú‚îÄ‚îÄ train/    # 33,595 im√°genes
‚îú‚îÄ‚îÄ val/      # 7,200 im√°genes
‚îî‚îÄ‚îÄ test/     # 7,199 im√°genes
```

---

### PASO 2: Generar Metadata
**Archivo:** `src/data/index_ffpp.py`

**Qu√© hace:**
- Escanea todas las im√°genes procesadas
- Genera CSV con: ruta, split (train/val/test), etiqueta (real/fake)
- **Output:** `data/processed/ffpp/ffpp_images_metadata.csv`

**Comando:**
```bash
python src/data/index_ffpp.py
```

---

### PASO 3: Entrenamiento del Modelo
**Archivo:** `src/models/train_resnet_ffpp.py`

**Qu√© hace:**
- Carga ResNet18 preentrenada en ImageNet
- Reemplaza √∫ltima capa: 1000 clases ‚Üí 2 clases (real/fake)
- Entrena 10 √©pocas con:
  - Ponderaci√≥n de clases (4.83 real, 1.00 fake)
  - Augmentation: RandomCrop, Flip, ColorJitter
  - Adam optimizer (lr=1e-4)
- Guarda mejor modelo seg√∫n validation accuracy
- **Output:** `models/deepfake_detector_resnet18_ffpp.pth`

**Comando:**
```bash
python src/models/train_resnet_ffpp.py
```

**Variables clave para cambiar:**
```python
MODEL_TYPE = "resnet18"  # o "custom", "custom_small"
batch_size = 64
num_epochs = 10
lr = 1e-4
```

**Output esperado:**
```
√âpoca 01/10 | Train loss: 0.5234, acc: 0.7845 | Val loss: 0.4321, acc: 0.8123
...
√âpoca 08/10 | Train loss: 0.2981, acc: 0.8934 | Val loss: 0.3913, acc: 0.8683
  üî• Nuevo mejor modelo guardado (val_acc: 0.8683)
```

---

### PASO 4: Evaluaci√≥n Detallada
**Archivo:** `src/models/evaluate_resnet_ffpp.py`

**Qu√© hace:**
- Carga modelo entrenado
- Eval√∫a en conjunto de test (7,199 im√°genes)
- Calcula matriz de confusi√≥n
- Muestra m√©tricas por clase (precision, recall, F1)
- **Output:** M√©tricas en terminal

**Comando:**
```bash
python src/models/evaluate_resnet_ffpp.py
```

**Output esperado:**
```
Test Accuracy: 88.67%
Test Loss: 0.3441

Matriz de Confusi√≥n:
              Predicci√≥n
           REAL    FAKE
REAL        983     158    (Recall: 86.15%)
FAKE        658    5400    (Recall: 89.14%)

Precision REAL: 59.90%
Precision FAKE: 97.16%
```

---

### PASO 5: Predicci√≥n en Nueva Imagen
**Archivo:** `src/models/predict_image.py`

**Qu√© hace:**
- Carga modelo entrenado
- Procesa imagen (resize 224√ó224, normalizaci√≥n)
- Predice clase (REAL/FAKE) y confianza
- **Output:** Predicci√≥n en terminal

**Comando:**
```bash
python src/models/predict_image.py ruta/a/imagen.jpg
```

**Output esperado:**
```
üì∏ Imagen: amigo2.jpeg
ü§ñ Predicci√≥n: REAL
üìä Confianza: 96.52%
```

---

### PASO 6: Grad-CAM (Explicabilidad)
**Archivo:** `src/models/analyze_amigos_simple.py`

**Qu√© hace:**
- Carga 5 im√°genes de prueba
- Aplica Grad-CAM en capa layer4 de ResNet18
- Genera 3 visualizaciones por imagen:
  1. Predicci√≥n normal
  2. An√°lisis forzado REAL
  3. An√°lisis forzado FAKE
- Crea grid comparativo de los 5 casos
- **Output:** Visualizaciones en `results/gradcam_amigos/`

**Comando:**
```bash
cd src/models
python analyze_amigos_simple.py
```

**Output esperado:**
```
Analizando amigo1.jpeg...
  Predicci√≥n: REAL (68.51%)
  ‚úì Guardado en results/gradcam_amigos/amigo1/

...

‚úì Grid completo guardado en results/gradcam_amigos/comparison_grid.png
```

---

### PASO 7: API REST (Despliegue)
**Archivo:** `src/api/main.py`

**Qu√© hace:**
- Levanta servidor FastAPI
- Endpoint `/predict` para subir imagen y obtener predicci√≥n
- Documentaci√≥n autom√°tica en `/docs`
- **Output:** API REST en puerto 8000

**Comando:**
```bash
cd src/api
uvicorn main:app --reload
```

**Uso:**
```bash
# Abrir en navegador
http://localhost:8000/docs

# O usar curl
curl -X POST "http://localhost:8000/predict" \
  -F "file=@imagen.jpg"
```

**Output esperado:**
```json
{
  "prediction": "REAL",
  "confidence": 0.9652,
  "probabilities": {
    "real": 0.9652,
    "fake": 0.0348
  }
}
```

---

## üîë ARCHIVOS CLAVE A ENTENDER

### 1. `src/datasets/ffpp_faces.py` (DataLoader)
**Funci√≥n:** Lee CSV metadata y carga im√°genes con transformaciones PyTorch

**C√≥digo esencial:**
```python
class FFPPFacesDataset(Dataset):
    def __init__(self, csv_path, split='train', transform=None):
        df = pd.read_csv(csv_path)
        self.data = df[df['split'] == split]  # Filtrar train/val/test
        
    def __getitem__(self, idx):
        img = Image.open(img_path)
        label = 0 if label_str == 'real' else 1  # 0=REAL, 1=FAKE
        return self.transform(img), label
```

---

### 2. `src/models/custom_cnn.py` (Arquitectura personalizada)
**Funci√≥n:** Define 2 CNNs desde cero (8.49M y 1.11M par√°metros)

**Arquitectura CNN Est√°ndar:**
- 4 bloques convolucionales (64‚Üí128‚Üí256‚Üí512 filtros)
- BatchNorm + ReLU + MaxPool
- Adaptive Average Pooling
- Clasificador: Dropout ‚Üí FC(512‚Üí256) ‚Üí Dropout ‚Üí FC(256‚Üí2)

---

### 3. `src/models/gradcam_simple.py` (Explicabilidad)
**Funci√≥n:** Implementa Grad-CAM para visualizar atenci√≥n del modelo

**Concepto:**
1. Forward pass ‚Üí obtiene activaciones de capa objetivo
2. Backward pass ‚Üí calcula gradientes respecto a clase predicha
3. Promedio ponderado: `CAM = ReLU(Œ£(gradientes √ó activaciones))`
4. Resize CAM a tama√±o de imagen y overlay con heatmap

**C√≥digo esencial:**
```python
# 1. Forward
output = model(input_tensor)
pred_idx = torch.argmax(output)

# 2. Backward
output[0, pred_idx].backward()

# 3. Grad-CAM
weights = gradients.mean(dim=(2, 3))  # Global average pooling
cam = torch.sum(weights[:, :, None, None] * activations, dim=1)
cam = F.relu(cam)  # ReLU para quedarse con activaciones positivas
```

---

## üìà CONCEPTOS CLAVE

### Transfer Learning (ResNet18)
- **Idea:** Usar pesos preentrenados en ImageNet (1.2M im√°genes)
- **Ventaja:** Modelo ya sabe extraer features visuales (bordes, texturas, formas)
- **Ajuste:** Solo reemplazar √∫ltima capa y entrenar con nuestro dataset

### Ponderaci√≥n de Clases
- **Problema:** Dataset desbalanceado (84% fake, 16% real)
- **Soluci√≥n:** Asignar mayor peso a clase minoritaria en loss function
  ```python
  weights = torch.tensor([4.83, 1.00])  # [REAL, FAKE]
  criterion = nn.CrossEntropyLoss(weight=weights)
  ```
- **Efecto:** Modelo no colapsa a predecir siempre "fake"

### Grad-CAM
- **Problema:** ¬øEn qu√© partes de la imagen se fija el modelo?
- **Soluci√≥n:** Visualizar activaciones de √∫ltima capa convolucional
- **Interpretaci√≥n:** Zonas rojas/amarillas = regiones importantes para decisi√≥n

---

## üéì ORDEN RECOMENDADO PARA ESTUDIAR

1. **Entender el flujo de datos:**
   - `extract_and_crop_ffpp.py` ‚Üí `index_ffpp.py` ‚Üí `ffpp_faces.py`

2. **Entender el entrenamiento:**
   - `train_resnet_ffpp.py` (ver bucle de entrenamiento y validaci√≥n)

3. **Entender la evaluaci√≥n:**
   - `evaluate_resnet_ffpp.py` (ver c√°lculo de m√©tricas)

4. **Entender Grad-CAM:**
   - `gradcam_simple.py` (ver hooks y generaci√≥n de CAM)

5. **Entender el despliegue:**
   - `src/api/main.py` (ver endpoints FastAPI)

---

## üöÄ COMANDOS R√ÅPIDOS

```bash
# Flujo completo desde cero
python src/data/extract_and_crop_ffpp.py   # ~2-3 horas
python src/data/index_ffpp.py              # ~1 min
python src/models/train_resnet_ffpp.py     # ~40 min (CPU)
python src/models/evaluate_resnet_ffpp.py  # ~2 min
cd src/models && python analyze_amigos_simple.py  # ~30 seg

# Solo predicci√≥n con modelo ya entrenado
python src/models/predict_image.py imagen.jpg

# API REST
cd src/api && uvicorn main:app --reload
```

---

## üìä RESULTADOS ESPERADOS

- **Accuracy en test:** 88.67%
- **Recall clase REAL:** 86.15%
- **Recall clase FAKE:** 89.14%
- **Precision clase FAKE:** 97.16% (muy confiable cuando predice fake)
- **Tiempo de inferencia:** ~100ms por imagen (CPU)
- **Validaci√≥n externa:** 100% en 5 fotos reales de amigos

---

**Autor:** Luis - Universidad del B√≠o-B√≠o  
**Fecha:** Diciembre 2025
